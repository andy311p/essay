One of the weaknesses of state-of-the-art approaches to AES is that they are not well suited for adversarially crafted input of grammatical but incoherent sequences of sentences. Farag et al. [15] tackled this problem by developing a neural model of local coherence that can effectively learn connectedness features between sentences. Using a framework for integrating and jointly training the local coherence model with state-of-the-art AES, they demonstrate its effectiveness on both the AES task and the task of flagging adversarial input.
Pennebaker et al. [14] analyzed a corpus of 50,000 CAEs using features based on 8 groups of function words (pronouns, articles, auxiliary verbs etc.). They then tried to show correlation between the features extracted from the essays, which indicate whether the language is categorical or dynamic, and the grades over students' four years of college. Their findings showed that higher grades were associated with greater article and preposition use, indicating categorical language, while lower grades were associated with greater use of auxiliary verbs, pronouns, adverbs, conjunctions and negations, indicating more dynamic language. The links between categorical and dynamic writing and academic performance hint at the cognitive styles rewarded by education institutions.
Alvero et al. [12] sought to investigate the potential of computational reading as a check up on implicit bias in holistic review. They used a unique corpus of 283,000 application essays submitted to a large, selective, state university to asses the extent to which applicant demographic characteristics can be inferred from their essays. Using Logistic Regression, they were able to predict gender and household income with high levels of accuracy. In another research, Arthurs et al. [13] investigate the bias in methods used to evaluate the quality of vectors. They accomplish this by using a dataset of 800,000 CAEs split into quartiles based on Reported Household Income (RHI). They train sets of word vectors on each of the quartile and test each set on intrinsic evaluation tasks. They reach the conclusion that the evaluation tasks themselves are biased towards the writing of higher income applicants.
Kanojia et al. [11] predicted Computer Science Graduation admission acceptance based on applicants Statement of Purpose. They created a unique dataset by manually collecting 50 Statements of Purpose from Elite Universities (acceptance rate <= 15%). For the classification they used three sets of features – a) Textual Features – Feature values based on the text of the essay, b) Word Embedding Based Features – Features based on average of vector values provided by pre-trained model on Google News Corpora, c) Similarity Score based and Error based features – Features based on Document Similarity, and other features based on errors in the document. They used conventional Machine Learning algorithms (LR, SVM, RFF) and simple deep learning approaches (FFNN, MLP) combined with standard K-fold cross validation to deal with the small size of the dataset. 


----------------------------------------------
However, the task of evaluating CAE is a bit different from AES. Writing a CAE is not part of an exam, therefor, it is not bound by time and external help and tools can be used. This usually leads to high quality essays with very few grammatical mistakes if at all. So basing a classifier based

The work done by Kanojia et al. checked the influence of different textual features of the essay on the applicant's acceptance. However, their dataset focused on Computer Science Graduates only, and due the small size of the dataset, they did not test deep neural networks, which showed great improvements over conventional ML algorithms in the past[?]. 




[11] - Is your Statement Purposeless? Predicting Computer Science Graduation Admission Acceptance based on Statement Of Purpose
[12] - AI and Holistic Review: Informing Human Reading in College Admissions
[13] - Whose Truth is the “Ground Truth”? College Admissions Essays and Bias in Word Vector Evaluation Methods
[14] - When Small Words Foretell Academic Success: The Case of College Admissions Essays
[15] - Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input
